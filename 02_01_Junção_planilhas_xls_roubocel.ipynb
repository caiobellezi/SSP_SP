{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "superior-quarter",
   "metadata": {},
   "source": [
    "# Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-despite",
   "metadata": {},
   "source": [
    "Após fazer a coleta dos dados do site da Secretaria de Segurança Publica - SP, agora é necessário concatenar todos os arquivos em um só, com o mesmo padrão de informações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-texas",
   "metadata": {},
   "source": [
    "## Importar as bibliotecas que serão utilizadas\n",
    "\n",
    "**Pandas** - Para manipulação de tabelas\n",
    "\n",
    "**os** - Para manipulação e leitura de arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "known-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-maria",
   "metadata": {},
   "source": [
    "## Selecão das colunas\n",
    "\n",
    "Selecionar as colunas que serão utilizadas, no total 54 colunas, os arquivos mais antigos possuiam 57 colunas as quais os dados foram apagados e nos arquivos mais recentes por um questão de privacidade. Essas colunas eram:\n",
    "\n",
    "* `NOME_PESSOA`\n",
    "* `RG`\n",
    "* `RG_UF`\n",
    "\n",
    "Com isso, será compiladas as seguintes colunas:\n",
    " * `ANO_BO` - Ano do BO \n",
    " * `NUM_BO` - Número do BO\n",
    " * `NUMERO_BOLETIM` -\n",
    " * `BO_INICIADO` -\n",
    " * `BO_EMITIDO` -\n",
    " * `DATAOCORRENCIA` -\n",
    " * `HORAOCORRENCIA` -\n",
    " * `PERIDOOCORRENCIA` -\n",
    " * `DATACOMUNICACAO` -\n",
    " * `DATAELABORACAO` -\n",
    " * `BO_AUTORIA` -\n",
    " * `FLAGRANTE` -\n",
    " * `NUMERO_BOLETIM_PRINCIPAL` -\n",
    " * `LOGRADOURO` - Logradouro\n",
    " * `NUMERO` - Número da rua\n",
    " * `BAIRRO` - Bairro\n",
    " * `CIDADE` - Cidade\n",
    " * `UF` - Unidade Federativa\n",
    " * `LATITUDE` - Posição geográfica (Latitude)\n",
    " * `LONGITUDE` - Posição geográfica (Longitude)\n",
    " * `DESCRICAOLOCAL` -\n",
    " * `EXAME` -\n",
    " * `SOLUCAO` -\n",
    " * `DELEGACIA_NOME` - Nome da Delegacia\n",
    " * `DELEGACIA_CIRCUNSCRICAO` -\n",
    " * `ESPECIE` -\n",
    " * `RUBRICA` -\n",
    " * `DESDOBRAMENTO` -\n",
    " * `STATUS` -\n",
    " * `TIPOPESSOA` -\n",
    " * `VITIMAFATAL` -\n",
    " * `NATURALIDADE` -\n",
    " * `NACIONALIDADE` -\n",
    " * `SEXO` - \n",
    " * `DATANASCIMENTO` -\n",
    " * `IDADE` -\n",
    " * `ESTADOCIVIL` -\n",
    " * `PROFISSAO` -\n",
    " * `GRAUINSTRUCAO` -\n",
    " * `CORCUTIS` -\n",
    " * `NATUREZAVINCULADA` -\n",
    " * `TIPOVINCULO` -\n",
    " * `RELACIONAMENTO` -\n",
    " * `PARENTESCO` -\n",
    " * `PLACA_VEICULO` -\n",
    " * `UF_VEICULO` -\n",
    " * `CIDADE_VEICULO` -\n",
    " * `DESCR_COR_VEICULO` -\n",
    " * `DESCR_MARCA_VEICULO` -\n",
    " * `ANO_FABRICACAO` -\n",
    " * `ANO_MODELO` -\n",
    " * `DESCR_TIPO_VEICULO` -\n",
    " * `QUANT_CELULAR` -\n",
    " * `MARCA_CELULAR` -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identified-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas desejadas\n",
    "cols = ['ANO_BO', 'NUM_BO', 'NUMERO_BOLETIM', 'BO_INICIADO', 'BO_EMITIDO',\n",
    "       'DATAOCORRENCIA', 'HORAOCORRENCIA', 'PERIDOOCORRENCIA',\n",
    "       'DATACOMUNICACAO', 'DATAELABORACAO', 'BO_AUTORIA', 'FLAGRANTE',\n",
    "       'NUMERO_BOLETIM_PRINCIPAL', 'LOGRADOURO', 'NUMERO', 'BAIRRO', 'CIDADE',\n",
    "       'UF', 'LATITUDE', 'LONGITUDE', 'DESCRICAOLOCAL', 'EXAME', 'SOLUCAO',\n",
    "       'DELEGACIA_NOME', 'DELEGACIA_CIRCUNSCRICAO', 'ESPECIE', 'RUBRICA',\n",
    "       'DESDOBRAMENTO', 'STATUS', 'TIPOPESSOA', 'VITIMAFATAL', 'NATURALIDADE',\n",
    "       'NACIONALIDADE', 'SEXO', 'DATANASCIMENTO', 'IDADE', 'ESTADOCIVIL',\n",
    "       'PROFISSAO', 'GRAUINSTRUCAO', 'CORCUTIS', 'NATUREZAVINCULADA',\n",
    "       'TIPOVINCULO', 'RELACIONAMENTO', 'PARENTESCO', 'PLACA_VEICULO',\n",
    "       'UF_VEICULO', 'CIDADE_VEICULO', 'DESCR_COR_VEICULO',\n",
    "       'DESCR_MARCA_VEICULO', 'ANO_FABRICACAO', 'ANO_MODELO',\n",
    "       'DESCR_TIPO_VEICULO', 'QUANT_CELULAR', 'MARCA_CELULAR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-aluminum",
   "metadata": {},
   "source": [
    "## Leitura das planilhas e junção em único arquivo\n",
    "\n",
    "Se faz necessário fazer uma varredura para todos os arquivos **`.xls`** na pasta __*data/*__ e então fazer a junção de todos estes arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collectible-employer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas totais:  2916556\n",
      "\n",
      "Total de arquivos concatenados: 132\n",
      "\n",
      "Dimensões do dataset: \n",
      "\t- 2916556 Linhas\n",
      "\t- 54 Colunas\n"
     ]
    }
   ],
   "source": [
    "path = 'data/roubo_celular/'\n",
    "\n",
    "directory = os.path.join(path) # Diretório onde estão salvos os arquivos .xls\n",
    "i=0 # Marcador criado para definir se é o primeiro arquivo ou não\n",
    "counter=0 #Contador de arquivos lidos\n",
    "\n",
    "\n",
    "for root,dirs,files in os.walk(directory): # root - Caminho lido | dirs - diretórios existentes dentro do caminho lido | files - arquivos existentes no caminho lido\n",
    "    \n",
    "    #Percorrer todos os arquivos um a um, e ler somente os arquivos com extensão .xls\n",
    "    for file in files:\n",
    "        if file.endswith(\".xls\"):\n",
    "            dftemp = pd.read_csv(path+file, sep='\\t', encoding='UTF-16LE', usecols=cols, low_memory=False) # leitura do arquivo .xls (\"corrompido\")\n",
    "            \n",
    "            if i==0: # Condição IF para determinar se é a primeira leitura e copiar o dataset para a variável \"df\"\n",
    "                df = dftemp.copy()\n",
    "                i = 1\n",
    "                del(dftemp) # Deletar a variável para não sobrecarregar a memória\n",
    "                \n",
    "            else: # Para os demais arquivos realizar a junção com o primeiro arquivo\n",
    "                df = df.append(dftemp, ignore_index=True)\n",
    "                del(dftemp) # Deletar a variável para não sobrecarregar a memória\n",
    "                \n",
    "            linhas = df.shape[0]\n",
    "            counter = counter + 1\n",
    "            \n",
    "print(\"Linhas totais: \", linhas)\n",
    "print('\\nTotal de arquivos concatenados:', counter)\n",
    "print('\\nDimensões do dataset: \\n\\t- {} Linhas\\n\\t- {} Colunas'.format(df.shape[0],df.shape[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-canada",
   "metadata": {},
   "source": [
    "## Salvar para arquivo CSV\n",
    "\n",
    "Após o processo finalizado, o arquivo será salvo na pasta **`data_cleaned`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "usual-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaned/roubo_celular2010_2020.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-ecology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
